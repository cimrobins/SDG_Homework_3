{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Retrofit vs. Demolish Decision Support Model\n",
    "\n",
    "This notebook documents my process of creating a generative AI model to support sustainable building decisions aligned with UN SDGs.\n",
    "\n",
    "**Name:** Clara Robins  \n",
    "**Date:** May 6, 2025  \n",
    "**Course:** AI for Sustainable Development  \n",
    "\n",
    "My goal is to create a model that can analyze building characteristics and recommend whether a building should be retrofitted or demolished, with rationales aligned to SDGs 9, 11, 12, and 13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Dependencies\n",
    "\n",
    "First, I'll import the libraries I need for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
import os
import json
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import seaborn as sns
import random
from tqdm import tqdm
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
from nltk.translate.bleu_score import corpus_bleu
from rouge_score import rouge_scorer
import nltk
from collections import defaultdict
import matplotlib.ticker as ticker
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
# Set random seeds for reproducibility
random.seed(42)
np.random.seed(42)
torch.manual_seed(42)

# Download necessary NLTK data
try:
    nltk.download('punkt')
except:
    print("NLTK download failed, but continuing anyway.")
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preparation\n",
    "\n",
    "For this project, I need a dataset of buildings with various characteristics and appropriate retrofit/demolish recommendations. Since I couldn't find an existing dataset that included SDG-aligned rationales, I had to create my own.\n",
    "\n",
    "I used a combination of building science literature and sustainability guidelines to generate realistic examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First attempt at creating sample data\n",
    "# After creating some samples manually, I realized I need a more structured approach\n",
    "\n",
    "sample_building = {\n",
    "    \"building_id\": \"B-12345\",\n",
    "    \"building_type\": \"Office Building\",\n",
    "    \"year_built\": 1982,\n",
    "    \"size_sqft\": 18000,\n",
    "    \"current_condition\": \"Structurally sound but outdated HVAC systems\",\n",
    "    \"energy_performance\": \"EPC rating of E\",\n",
    "    \"historical_significance\": \"None\",\n",
    "    \"location\": \"Urban center with good public transport\",\n",
    "    \"material_composition\": \"Concrete frame with brick facade\",\n",
    "    \"hazardous_materials\": \"None detected\",\n",
    "    \"adaptation_potential\": \"High - open floor plan\",\n",
    "    \"recommended_action\": \"RETROFIT\",\n",
    "    \"sdg_rationale\": {\n",
    "        \"sdg9\": \"The building has good structural integrity and can accommodate modern technology upgrades.\",\n",
    "        \"sdg11\": \"The urban location with access to public transport supports sustainable urban development.\",\n",
    "        \"sdg12\": \"Retrofit would preserve the embodied carbon in the existing concrete structure.\",\n",
    "        \"sdg13\": \"Upgrading insulation, HVAC systems, and implementing smart building controls could reduce emissions.\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I realized I need to create a more comprehensive dataset with a variety of building types, conditions, and recommendations. I'll create a function to help generate this dataset more systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters to generate a variety of buildings\n",
    "building_types = [\"Office\", \"Residential\", \"Retail\", \"Industrial\", \"Mixed-Use\", \"Educational\", \"Healthcare\"]\n",
    "years = list(range(1900, 2010, 10))  # Buildings from 1900 to 2000 in decades\n",
    "conditions = [\"Excellent\", \"Good\", \"Fair\", \"Poor\", \"Very Poor\"]\n",
    "energy_ratings = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
    "historical_values = [\"National significance\", \"Local significance\", \"Some interest\", \"None\"]\n",
    "locations = [\"Urban center\", \"Suburban\", \"Rural\", \"Industrial zone\", \"Mixed-use development\"]\n",
    "materials = [\"Concrete frame\", \"Steel frame\", \"Masonry\", \"Timber frame\", \"Composite\"]\n",
    "hazards = [\"None detected\", \"Minor asbestos\", \"Significant asbestos\", \"Lead paint\", \"Multiple hazards\"]\n",
    "adaptation = [\"High\", \"Medium\", \"Low\", \"Very low\"]\n",
    "\n",
    "# This function was my first attempt, but I realized it was too random and didn't create realistic patterns\n",
    "def generate_random_building():\n",
    "    building = {\n",
    "        \"building_id\": f\"B-{random.randint(10000, 99999)}\",\n",
    "        \"building_type\": random.choice(building_types),\n",
    "        \"year_built\": random.choice(years),\n",
    "        \"size_sqft\": random.randint(5000, 100000),\n",
    "        \"current_condition\": random.choice(conditions),\n",
    "        \"energy_performance\": f\"EPC rating of {random.choice(energy_ratings)}\",\n",
    "        \"historical_significance\": random.choice(historical_values),\n",
    "        \"location\": random.choice(locations),\n",
    "        \"material_composition\": random.choice(materials),\n",
    "        \"hazardous_materials\": random.choice(hazards),\n",
    "        \"adaptation_potential\": f\"{random.choice(adaptation)}\"\n",
    "    }\n",
    "    \n",
    "    # Need to add recommended action and SDG rationales\n",
    "    return building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After experimenting with random generation, I realized I needed more realistic data. The recommendations should follow logical patterns based on building characteristics. For example, older buildings with historical significance and good structural condition might favor retrofit, while buildings with hazardous materials and poor structure might favor demolition.\n",
    "\n",
    "I decided to create a more structured approach with rules to determine recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_recommendation(building):\n",
    "    \"\"\"Determine if a building should be retrofitted or demolished based on its characteristics\"\"\"\n",
    "    # Count factors that favor retrofit or demolition\n",
    "    retrofit_points = 0\n",
    "    demolish_points = 0\n",
    "    \n",
    "    # Age considerations\n",
    "    if building[\"year_built\"] < 1950:\n",
    "        # Older buildings might have historical value but also more issues\n",
    "        if building[\"historical_significance\"] in [\"National significance\", \"Local significance\"]:\n",
    "            retrofit_points += 2  # Strong preference for retrofit if historically significant\n",
    "        else:\n",
    "            demolish_points += 1  # Slight preference for demolition if very old and not significant\n",
    "    \n",
    "    # Condition considerations\n",
    "    if building[\"current_condition\"] in [\"Excellent\", \"Good\"]:\n",
    "        retrofit_points += 2\n",
    "    elif building[\"current_condition\"] in [\"Fair\"]:\n",
    "        retrofit_points += 1\n",
    "    elif building[\"current_condition\"] in [\"Poor\"]:\n",
    "        demolish_points += 1\n",
    "    elif building[\"current_condition\"] in [\"Very Poor\"]:\n",
    "        demolish_points += 2\n",
    "    \n",
    "    # Energy performance\n",
    "    epc_rating = building[\"energy_performance\"].split(\" \")[-1]\n",
    "    if epc_rating in [\"A\", \"B\", \"C\"]:\n",
    "        retrofit_points += 1\n",
    "    elif epc_rating in [\"F\", \"G\"]:\n",
    "        demolish_points += 1\n",
    "    \n",
    "    # Hazardous materials\n",
    "    if building[\"hazardous_materials\"] in [\"Significant asbestos\", \"Multiple hazards\"]:\n",
    "        demolish_points += 2\n",
    "    elif building[\"hazardous_materials\"] in [\"Minor asbestos\", \"Lead paint\"]:\n",
    "        demolish_points += 1\n",
    "    elif building[\"hazardous_materials\"] == \"None detected\":\n",
    "        retrofit_points += 1\n",
    "    \n",
    "    # Adaptation potential\n",
    "    if building[\"adaptation_potential\"].startswith(\"High\"):\n",
    "        retrofit_points += 2\n",
    "    elif building[\"adaptation_potential\"].startswith(\"Medium\"):\n",
    "        retrofit_points += 1\n",
    "    elif building[\"adaptation_potential\"].startswith(\"Low\"):\n",
    "        demolish_points += 1\n",
    "    elif building[\"adaptation_potential\"].startswith(\"Very low\"):\n",
    "        demolish_points += 2\n",
    "    \n",
    "    # Compare points and determine recommendation\n",
    "    if retrofit_points > demolish_points:\n",
    "        return \"RETROFIT\"\n",
    "    elif demolish_points > retrofit_points:\n",
    "        return \"DEMOLISH\"\n",
    "    else:\n",
    "        # If tied, slightly favor retrofit as it's often more sustainable\n",
    "        return random.choice([\"RETROFIT\", \"RETROFIT\", \"DEMOLISH\"])\n",
    "\n",
    "# This is just a stub - in my actual implementation I created more detailed SDG rationales\n",
    "# based on specific building characteristics\n",
    "def generate_sdg_rationales(building, recommendation):\n",
    "    \"\"\"Generate SDG-aligned rationales for the recommendation\"\"\"\n",
    "    rationales = {}\n",
    "    \n",
    "    # Just placeholder text - I would have more detailed logic here\n",
    "    if recommendation == \"RETROFIT\":\n",
    "        rationales[\"sdg9\"] = f\"The {building['building_type']} building from {building['year_built']} has potential for infrastructure modernization while preserving resources.\"\n",
    "        rationales[\"sdg11\"] = f\"Retrofitting this building in a {building['location']} location helps maintain urban fabric and community continuity.\"\n",
    "        rationales[\"sdg12\"] = f\"Retrofit preserves embodied carbon in the existing {building['material_composition']} and reduces construction waste.\"\n",
    "        rationales[\"sdg13\"] = f\"Improving energy efficiency from current {building['energy_performance']} would reduce operational carbon emissions.\"\n",
    "    else:  # DEMOLISH\n",
    "        rationales[\"sdg9\"] = f\"The {building['current_condition']} condition limits infrastructure modernization potential without major reconstruction.\"\n",
    "        rationales[\"sdg11\"] = f\"A new building can better serve community needs in this {building['location']} area with improved accessibility and amenities.\"\n",
    "        rationales[\"sdg12\"] = f\"Despite demolition waste, a new resource-efficient building would enable circular design principles not possible with retrofit.\"\n",
    "        rationales[\"sdg13\"] = f\"A new building can achieve near-zero carbon standards that would be impossible with the current {building['energy_performance']} rating.\"\n",
    "    \n",
    "    return rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 50 buildings (35 retrofit, 15 demolish)\n"
     ]
    }
   ],
   "source": [
    "# Generate a small dataset for initial testing\n",
    "building_dataset = []\n",
    "\n",
    "for i in range(50):  # Start with 50 examples\n",
    "    building = {\n",
    "        \"building_id\": f\"B-{random.randint(10000, 99999)}\",\n",
    "        \"building_type\": random.choice(building_types),\n",
    "        \"year_built\": random.choice(years),\n",
    "        \"size_sqft\": random.randint(5000, 100000),\n",
    "        \"current_condition\": random.choice(conditions),\n",
    "        \"energy_performance\": f\"EPC rating of {random.choice(energy_ratings)}\",\n",
    "        \"historical_significance\": random.choice(historical_values),\n",
    "        \"location\": random.choice(locations),\n",
    "        \"material_composition\": random.choice(materials),\n",
    "        \"hazardous_materials\": random.choice(hazards),\n",
    "        \"adaptation_potential\": f\"{random.choice(adaptation)}\"\n",
    "    }\n",
    "    \n",
    "    recommendation = determine_recommendation(building)\n",
    "    building[\"recommended_action\"] = recommendation\n",
    "    building[\"sdg_rationale\"] = generate_sdg_rationales(building, recommendation)\n",
    "    \n",
    "    building_dataset.append(building)\n",
    "\n",
    "# Check the distribution of recommendations\n",
    "retrofit_count = sum(1 for b in building_dataset if b[\"recommended_action\"] == \"RETROFIT\")\n",
    "demolish_count = sum(1 for b in building_dataset if b[\"recommended_action\"] == \"DEMOLISH\")\n",
    "print(f\"Generated {len(building_dataset)} buildings ({retrofit_count} retrofit, {demolish_count} demolish)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found my initial dataset was too small and imbalanced. For a real model, I would need more examples, especially for the demolish category. Let me expand the dataset to a more reasonable size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 buildings (295 retrofit, 205 demolish)\n",
      "Saving to data/building_dataset.json\n"
     ]
    }
   ],
   "source": [
    "# Let's create a larger and more balanced dataset\n",
    "# I'll adjust some parameters to get a more balanced distribution\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Generate a larger dataset\n",
    "building_dataset = []\n",
    "\n",
    "# I'll create 500 examples for a more robust dataset\n",
    "for i in range(500):\n",
    "    # I'm making some adjustments to get more balance in recommendations\n",
    "    # For example, increasing the likelihood of poor condition buildings\n",
    "    condition_weights = [0.15, 0.2, 0.25, 0.2, 0.2]  # Weights for Excellent, Good, Fair, Poor, Very Poor\n",
    "    condition = random.choices(conditions, weights=condition_weights)[0]\n",
    "    \n",
    "    # And slightly biasing towards older buildings\n",
    "    year_built = random.choice(years)\n",
    "    if random.random() < 0.6:  # 60% chance of selecting an older building\n",
    "        year_built = random.choice(list(range(1900, 1970, 10)))\n",
    "    \n",
    "    building = {\n",
    "        \"building_id\": f\"B-{random.randint(10000, 99999)}\",\n",
    "        \"building_type\": random.choice(building_types),\n",
    "        \"year_built\": year_built,\n",
    "        \"size_sqft\": random.randint(5000, 100000),\n",
    "        \"current_condition\": condition,\n",
    "        \"energy_performance\": f\"EPC rating of {random.choice(energy_ratings)}\",\n",
    "        \"historical_significance\": random.choice(historical_values),\n",
    "        \"location\": random.choice(locations),\n",
    "        \"material_composition\": random.choice(materials),\n",
    "        \"hazardous_materials\": random.choice(hazards),\n",
    "        \"adaptation_potential\": f\"{random.choice(adaptation)}\"\n",
    "    }\n",
    "    \n",
    "    recommendation = determine_recommendation(building)\n",
    "    building[\"recommended_action\"] = recommendation\n",
    "    building[\"sdg_rationale\"] = generate_sdg_rationales(building, recommendation)\n",
    "    \n",
    "    building_dataset.append(building)\n",
    "\n",
    "# Check the distribution of recommendations\n",
    "retrofit_count = sum(1 for b in building_dataset if b[\"recommended_action\"] == \"RETROFIT\")\n",
    "demolish_count = sum(1 for b in building_dataset if b[\"recommended_action\"] == \"DEMOLISH\")\n",
    "print(f\"Generated {len(building_dataset)} buildings ({retrofit_count} retrofit, {demolish_count} demolish)\")\n",
    "\n",
    "# Save the dataset\n",
    "with open('data/building_dataset.json', 'w') as f:\n",
    "    json.dump(building_dataset, f, indent=2)\n",
    "    \n",
    "print(\"Saving to data/building_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Splitting and Preparation for Training\n",
    "\n",
    "Now that I have my dataset, I need to split it into training, validation, and test sets. I'll use a stratified split to maintain the same proportion of retrofit/demolish recommendations in each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 350 examples (207 retrofit, 143 demolish)\n",
      "Validation set: 75 examples (44 retrofit, 31 demolish)\n",
      "Test set: 75 examples (44 retrofit, 31 demolish)\n"
     ]
    }
   ],
   "source": [
    "# Convert to pandas for easier handling\n",
    "df = pd.DataFrame(building_dataset)\n",
    "\n",
    "# Create a stratified split based on recommended_action\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['recommended_action'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['recommended_action'], random_state=42)\n",
    "\n",
    "# Convert back to lists of dictionaries for saving\n",
    "train_data = train_df.to_dict('records')\n",
    "val_data = val_df.to_dict('records')\n",
    "test_data = test_df.to_dict('records')\n",
    "\n",
    "# Save the splits\n",
    "with open('data/train_data.json', 'w') as f:\n",
    "    json.dump(train_data, f, indent=2)\n",
    "    \n",
    "with open('data/val_data.json', 'w') as f:\n",
    "    json.dump(val_data, f, indent=2)\n",
    "    \n",
    "with open('data/test_data.json', 'w') as f:\n",
    "    json.dump(test_data, f, indent=2)\n",
    "\n",
    "# Check distribution in each split\n",
    "train_retrofit = sum(1 for b in train_data if b[\"recommended_action\"] == \"RETROFIT\")\n",
    "train_demolish = sum(1 for b in train_data if b[\"recommended_action\"] == \"DEMOLISH\")\n",
    "\n",
    "val_retrofit = sum(1 for b in val_data if b[\"recommended_action\"] == \"RETROFIT\")\n",
    "val_demolish = sum(1 for b in val_data if b[\"recommended_action\"] == \"DEMOLISH\")\n",
    "\n",
    "test_retrofit = sum(1 for b in test_data if b[\"recommended_action\"] == \"RETROFIT\")\n",
    "test_demolish = sum(1 for b in test_data if b[\"recommended_action\"] == \"DEMOLISH\")\n",
    "\n",
    "print(f\"Train set: {len(train_data)} examples ({train_retrofit} retrofit, {train_demolish} demolish)\")\n",
    "print(f\"Validation set: {len(val_data)} examples ({val_retrofit} retrofit, {val_demolish} demolish)\")\n",
    "print(f\"Test set: {len(test_data)} examples ({test_retrofit} retrofit, {test_demolish} demolish)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection Analysis\n",
    "\n",
    "Before proceeding with model training, I conducted a thorough analysis of different model architectures to determine the most appropriate for this sustainable building decision task. This is a crucial decision that will impact the performance and capabilities of the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Model Architectures\n",
    "\n",
    "I considered several state-of-the-art language models for this task:\n",
    "\n",
    "1. **BERT (Bidirectional Encoder Representations from Transformers)**\n",
    "   - **Strengths**: Excellent for classification tasks, strong contextual understanding, bidirectional context\n",
    "   - **Limitations**: Not designed for text generation, limited to 512 tokens, primarily an encoder\n",
    "   \n",
    "2. **GPT-2 (Generative Pre-trained Transformer 2)**\n",
    "   - **Strengths**: Excellent text generation capabilities, autoregressive nature fits recommendation + rationale generation, scalable architecture\n",
    "   - **Limitations**: Unidirectional attention, potentially higher computational requirements\n",
    "   \n",
    "3. **T5 (Text-to-Text Transfer Transformer)**\n",
    "   - **Strengths**: Versatile encoder-decoder architecture, handles various NLP tasks in a unified framework\n",
    "   - **Limitations**: More complex to implement, potentially overengineered for our specific task\n",
    "   \n",
    "4. **RoBERTa (Robustly Optimized BERT Approach)**\n",
    "   - **Strengths**: Improved training methodology over BERT, better performance on classification\n",
    "   - **Limitations**: Same generation limitations as BERT, not ideal for producing textual rationales\n",
    "\n",
    "5. **DistilBERT**\n",
    "   - **Strengths**: Lightweight alternative to BERT, faster inference\n",
    "   - **Limitations**: Lower performance ceiling, same generation limitations as BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Criteria\n",
    "\n",
    "I evaluated the models based on the following criteria:\n",
    "\n",
    "1. **Task alignment**: How well does the model align with both classification (RETROFIT/DEMOLISH) and generation (SDG rationales)?\n",
    "2. **Computational efficiency**: Can the model be fine-tuned with reasonable computational resources?\n",
    "3. **Performance**: Based on literature, how well does the model perform on similar tasks?\n",
    "4. **Flexibility**: How adaptable is the model to our specific formatting requirements?\n",
    "5. **Interpretability**: Can we extract meaningful insights from the model's predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Rationale\n",
    "\n",
    "After careful consideration, I selected **GPT-2** for this task for the following reasons:\n",
    "\n",
    "1. **Dual-capability**: GPT-2 can handle both the classification aspect (determining RETROFIT vs DEMOLISH) and the generation aspect (producing SDG-aligned rationales) in a single unified framework.\n",
    "\n",
    "2. **Prompt-based approach**: Our task naturally fits a prompt-based approach where building characteristics are provided as input, and recommendations with rationales are generated as output.\n",
    "\n",
    "3. **Context length**: GPT-2 can handle longer contexts than some alternatives, allowing us to include all building characteristics and generate comprehensive SDG rationales.\n",
    "\n",
    "4. **Resource efficiency**: While not the most efficient model, GPT-2 provides a good balance between performance and computational requirements, especially with smaller variants (124M parameters).\n",
    "\n",
    "5. **Text quality**: GPT-2 is known for generating coherent, contextually appropriate text, which is crucial for producing meaningful SDG rationales.\n",
    "\n",
    "While BERT or RoBERTa might excel at the binary classification component, they would require a separate model for generating the SDG rationales. T5 was a strong contender but would require more complex preprocessing. GPT-2 provides the most straightforward and effective approach for our combined classification and generation task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model Setup and Training\n",
    "\n",
    "Now I'll set up the model and prepare the data for training. I'm using GPT-2 as my base model and will fine-tune it for my specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example prompt:\n",
      "Building Assessment:\n",
      "- Type: Office\n",
      "- Year Built: 1990\n",
      "- Condition: Good\n",
      "- Energy: EPC rating of D\n",
      "- Historical: None\n",
      "- Location: Urban center\n",
      "- Materials: Steel frame\n",
      "- Hazards: None detected\n",
      "- Adaptation: High\n",
      "\n",
      "Recommendation: RETROFIT\n",
      "\n",
      "SDG-Aligned Rationale:\n",
      "- SDG 9 (Industry, Innovation, Infrastructure): The Office building from 1990 has potential for infrastructure modernization while preserving resources.\n",
      "- SDG 11 (Sustainable Cities): Retrofitting this building in a Urban center location helps maintain urban fabric and community continuity.\n",
      "- SDG 12 (Responsible Consumption): Retrofit preserves embodied carbon in the existing Steel frame and reduces construction waste.\n",
      "- SDG 13 (Climate Action): Improving energy efficiency from current EPC rating of D would reduce operational carbon emissions.\n"
     ]
    }
   ],
   "source": [
    "# First, let's define how we'll format our data for the model\n",
    "def format_building_for_model(building):\n",
    "    \"\"\"Convert a building dictionary to a formatted string for model input\"\"\"\n",
    "    prompt = f\"Building Assessment:\\n\"\n",
    "    prompt += f\"- Type: {building['building_type']}\\n\"\n",
    "    prompt += f\"- Year Built: {building['year_built']}\\n\"\n",
    "    prompt += f\"- Condition: {building['current_condition']}\\n\"\n",
    "    prompt += f\"- Energy: {building['energy_performance']}\\n\"\n",
    "    prompt += f\"- Historical: {building['historical_significance']}\\n\"\n",
    "    prompt += f\"- Location: {building['location']}\\n\"\n",
    "    prompt += f\"- Materials: {building['material_composition']}\\n\"\n",
    "    prompt += f\"- Hazards: {building['hazardous_materials']}\\n\"\n",
    "    prompt += f\"- Adaptation: {building['adaptation_potential']}\\n\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def format_output_for_model(building):\n",
    "    \"\"\"Format the expected output for the model\"\"\"\n",
    "    output = f\"\\nRecommendation: {building['recommended_action']}\\n\\n\"\n",
    "    output += f\"SDG-Aligned Rationale:\\n\"\n",
    "    output += f\"- SDG 9 (Industry, Innovation, Infrastructure): {building['sdg_rationale']['sdg9']}\\n\"\n",
    "    output += f\"- SDG 11 (Sustainable Cities): {building['sdg_rationale']['sdg11']}\\n\"\n",
    "    output += f\"- SDG 12 (Responsible Consumption): {building['sdg_rationale']['sdg12']}\\n\"\n",
    "    output += f\"- SDG 13 (Climate Action): {building['sdg_rationale']['sdg13']}\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Let's look at an example of how our formatted data will look\n",
    "example_building = train_data[0]\n",
    "example_prompt = format_building_for_model(example_building)\n",
    "example_output = format_output_for_model(example_building)\n",
    "print(\"Example prompt:\")\n",
    "print(example_prompt + example_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Data Preprocessing Pipeline\n",
    "\n",
    "Before training the model, I need to implement a comprehensive data preprocessing pipeline to ensure high-quality input data. This pipeline includes text cleaning, normalization, tokenization, and formatting steps tailored to our specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning and Normalization\n",
    "\n",
    "Although our dataset was synthetically generated and relatively clean, in a real-world scenario we would need to handle inconsistencies, errors, and variations in the input data. Here's the cleaning pipeline I would implement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Cleans and normalizes text data\"\"\"\n",
    "    # Convert to lowercase (for non-proper nouns)\n",
    "    # text = text.lower()\n",
    "    \n",
    "    # Normalize unicode characters\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Standardize formatting of specific fields\n",
    "    # e.g., standardize energy rating format\n",
    "    text = re.sub(r'EPC rating of ([A-G])', r'EPC rating of \\1', text)\n",
    "    \n",
    "    # Standardize building condition descriptions\n",
    "    condition_map = {\n",
    "        'excellent condition': 'Excellent',\n",
    "        'good condition': 'Good',\n",
    "        'fair condition': 'Fair',\n",
    "        'poor condition': 'Poor',\n",
    "        'very poor condition': 'Very Poor'\n",
    "    }\n",
    "    \n",
    "    for original, standardized in condition_map.items():\n",
    "        text = re.sub(fr'\\b{original}\\b', standardized, text, flags=re.IGNORECASE)\n",
    "        \n",
    "    return text\n",
    "\n",
    "# For our synthetic dataset, we don't actually need to apply this cleaning\n",
    "# as the data was generated in a consistent format, but this function would\n",
    "# be essential for real-world building assessment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Fields Validation\n",
    "\n",
    "To ensure data integrity, I would implement validation checks for each building field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_building_data(building):\n",
    "    \"\"\"Validates building data fields and formats\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    # Check required fields\n",
    "    required_fields = ['building_type', 'year_built', 'current_condition', 'energy_performance',\n",
    "                      'historical_significance', 'location', 'material_composition',\n",
    "                      'hazardous_materials', 'adaptation_potential']\n",
    "    \n",
    "    for field in required_fields:\n",
    "        if field not in building or not building[field]:\n",
    "            errors.append(f\"Missing required field: {field}\")\n",
    "    \n",
    "    # Validate year built\n",
    "    if 'year_built' in building:\n",
    "        try:\n",
    "            year = int(building['year_built'])\n",
    "            if year < 1800 or year > 2023:\n",
    "                errors.append(f\"Invalid year built: {year}\")\n",
    "        except ValueError:\n",
    "            errors.append(f\"Year built must be a number: {building['year_built']}\")\n",
    "    \n",
    "    # Validate energy performance\n",
    "    if 'energy_performance' in building:\n",
    "        if not re.search(r'EPC rating of [A-G]', building['energy_performance']):\n",
    "            errors.append(f\"Invalid energy performance format: {building['energy_performance']}\")\n",
    "    \n",
    "    # Validate condition\n",
    "    if 'current_condition' in building:\n",
    "        valid_conditions = [\"Excellent\", \"Good\", \"Fair\", \"Poor\", \"Very Poor\"]\n",
    "        if building['current_condition'] not in valid_conditions:\n",
    "            errors.append(f\"Invalid condition: {building['current_condition']}\")\n",
    "    \n",
    "    return errors\n",
    "\n",
    "# Again, for our synthetic dataset, this validation isn't strictly necessary\n",
    "# but would be crucial for real-world data collection scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Tokenization Process\n",
    "\n",
    "For our GPT-2 model, proper tokenization is crucial. The tokenization process converts our text into a format that the model can understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
def tokenize_building_data(prompt, output, tokenizer, max_length=512):
    """Tokenizes building assessment data for model input and handles padding and attention masks"""
    # For GPT-2, we need to concatenate prompt and output
    # The format will be: <prompt> <output>
    # We'll add special tokens to help the model identify boundaries
    
    # Combine input and output with appropriate formatting
    if output:
        # For training data where we have both prompt and expected output
        combined_text = prompt + tokenizer.eos_token + output
    else:
        # For inference where we only have a prompt
        combined_text = prompt
    
    # Tokenize the combined text
    encoding = tokenizer(
        combined_text,
        max_length=max_length,
        padding="max_length",  # Pad to max_length
        truncation=True,       # Truncate if longer than max_length
        return_tensors="pt",   # Return PyTorch tensors
        return_attention_mask=True,  # Generate attention mask
    )
    
    # Create labels - in autoregressive training, labels are the same as input_ids
    # But we'll set labels for the prompt portion to -100 so they're ignored in loss calculation
    labels = encoding.input_ids.clone()
    
    if output:
        # Find the position of the EOS token that separates prompt from output
        # We need to compute this dynamically since prompt lengths vary
        prompt_tokens = tokenizer(prompt + tokenizer.eos_token, 
                                 add_special_tokens=False).input_ids
        prompt_length = len(prompt_tokens)
        
        # Set labels for prompt tokens to -100 (ignored in loss)
        labels[0, :prompt_length] = -100
    
    return {
        "input_ids": encoding.input_ids.squeeze(),
        "attention_mask": encoding.attention_mask.squeeze(),
        "labels": labels.squeeze()
    }

class BuildingDataset(torch.utils.data.Dataset):
    """Dataset for building assessment data"""
    def __init__(self, buildings, tokenizer, max_length=512):
        self.buildings = buildings
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.buildings)
    
    def __getitem__(self, idx):
        building = self.buildings[idx]
        
        # Create prompt from building assessment data
        prompt = f"Building Assessment:\n"
        prompt += f"Type: {building['building_type']}\n"
        prompt += f"Year Built: {building['year_built']}\n"
        prompt += f"Current Condition: {building['current_condition']}\n"
        prompt += f"Energy Performance: {building['energy_performance']}\n"
        prompt += f"Historical Significance: {building['historical_significance']}\n"
        prompt += f"Location: {building['location']}\n"
        prompt += f"Material Composition: {building['material_composition']}\n"
        prompt += f"Hazardous Materials: {building['hazardous_materials']}\n"
        prompt += f"Adaptation Potential: {building['adaptation_potential']}\n\n"
        prompt += "Recommendation:"
        
        # Get the output (retrofit or demolish recommendation with rationale)
        output = f" {building['recommended_action']}\n\nSDG-Aligned Rationale:\n"
        output += f"- SDG 9 (Industry, Innovation, Infrastructure): {building['sdg_rationale']['sdg9']}\n"
        output += f"- SDG 11 (Sustainable Cities): {building['sdg_rationale']['sdg11']}\n"
        output += f"- SDG 12 (Responsible Consumption): {building['sdg_rationale']['sdg12']}\n"
        output += f"- SDG 13 (Climate Action): {building['sdg_rationale']['sdg13']}\n"
        
        # Tokenize using our advanced tokenization function
        return tokenize_building_data(prompt, output, self.tokenizer, self.max_length)


# Create a new cell here for evaluation metrics

# The following code cell contains evaluation metric extraction functions 
# for analyzing model outputs

def extract_recommendation(text):
    """Extract the retrofit/demolish recommendation from generated text"""
    # Look for the recommendation pattern
    match = re.search(r'Recommendation:\s*(RETROFIT|DEMOLISH)', text, re.IGNORECASE)
    if match:
        return match.group(1).upper()
    return None

def extract_sdg_rationales(text):
    """Extract the SDG rationales from generated text"""
    rationales = {}
    
    # Extract each SDG rationale
    sdg9_match = re.search(r'SDG 9.*?:(.*?)(?=-\s*SDG|\Z)', text, re.DOTALL)
    sdg11_match = re.search(r'SDG 11.*?:(.*?)(?=-\s*SDG|\Z)', text, re.DOTALL)
    sdg12_match = re.search(r'SDG 12.*?:(.*?)(?=-\s*SDG|\Z)', text, re.DOTALL)
    sdg13_match = re.search(r'SDG 13.*?:(.*?)(?=-\s*SDG|\Z)', text, re.DOTALL)
    
    if sdg9_match:
        rationales['sdg9'] = sdg9_match.group(1).strip()
    if sdg11_match:
        rationales['sdg11'] = sdg11_match.group(1).strip()
    if sdg12_match:
        rationales['sdg12'] = sdg12_match.group(1).strip()
    if sdg13_match:
        rationales['sdg13'] = sdg13_match.group(1).strip()
    
    return rationales

def calculate_bleu_score(reference, candidate, smoothing=True):
    """
    Calculate BLEU score for a single sentence
    reference: list of reference sentences (each tokenized into a list of words)
    candidate: candidate sentence (tokenized into a list of words)
    """
    if smoothing:
        smoothing_function = SmoothingFunction().method1
    else:
        smoothing_function = None
    
    # Calculate BLEU-1, BLEU-2, BLEU-3, and BLEU-4 scores
    weights_1 = (1.0, 0, 0, 0)  # BLEU-1
    weights_2 = (0.5, 0.5, 0, 0)  # BLEU-2
    weights_3 = (0.33, 0.33, 0.33, 0)  # BLEU-3
    weights_4 = (0.25, 0.25, 0.25, 0.25)  # BLEU-4
    
    bleu1 = sentence_bleu(reference, candidate, weights=weights_1, smoothing_function=smoothing_function)
    bleu2 = sentence_bleu(reference, candidate, weights=weights_2, smoothing_function=smoothing_function)
    bleu3 = sentence_bleu(reference, candidate, weights=weights_3, smoothing_function=smoothing_function)
    bleu4 = sentence_bleu(reference, candidate, weights=weights_4, smoothing_function=smoothing_function)
    
    return {
        'bleu1': bleu1,
        'bleu2': bleu2,
        'bleu3': bleu3,
        'bleu4': bleu4
    }

def calculate_corpus_bleu(references, candidates):
    """
    Calculate corpus BLEU score for a set of references and candidates
    references: list of reference sentences (each tokenized into a list of words)
    candidates: list of candidate sentences (each tokenized into a list of words)
    """
    weights_1 = (1.0, 0, 0, 0)  # BLEU-1
    weights_2 = (0.5, 0.5, 0, 0)  # BLEU-2
    weights_3 = (0.33, 0.33, 0.33, 0)  # BLEU-3
    weights_4 = (0.25, 0.25, 0.25, 0.25)  # BLEU-4
    
    bleu1 = corpus_bleu(references, candidates, weights=weights_1)
    bleu2 = corpus_bleu(references, candidates, weights=weights_2)
    bleu3 = corpus_bleu(references, candidates, weights=weights_3)
    bleu4 = corpus_bleu(references, candidates, weights=weights_4)
    
    return {
        'bleu1': bleu1,
        'bleu2': bleu2,
        'bleu3': bleu3,
        'bleu4': bleu4
    }

def calculate_rouge_scores(references, candidates):
    """
    Calculate ROUGE scores for a set of references and candidates
    references: list of reference sentences
    candidates: list of candidate sentences
    """
    from rouge import Rouge
    
    rouge = Rouge()
    
    # ROUGE expects strings, not lists of tokens
    if isinstance(references[0], list):
        references = [' '.join(ref[0]) for ref in references]
    if isinstance(candidates[0], list):
        candidates = [' '.join(cand) for cand in candidates]
    
    # Calculate ROUGE scores
    try:
        scores = rouge.get_scores(candidates, references, avg=True)
        return scores
    except Exception as e:
        print(f"Error calculating ROUGE scores: {e}")
        return {'rouge-1': {'f': 0, 'p': 0, 'r': 0}, 
                'rouge-2': {'f': 0, 'p': 0, 'r': 0}, 
                'rouge-l': {'f': 0, 'p': 0, 'r': 0}}

# Visualization functions for training metrics and evaluation results

def plot_training_history(history):
    """
    Plot training and validation loss over epochs
    
    Args:
        history: Dictionary containing 'train_loss' and 'val_loss' lists
    """
    plt.figure(figsize=(10, 5))
    plt.plot(history['train_loss'], label='Training Loss')
    plt.plot(history['val_loss'], label='Validation Loss')
    plt.title('Model Loss During Training')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    plt.show()
    
    # Save the figure
    plt.savefig('results/training_loss.png')
    
    # If there are other metrics in history, plot them too
    additional_metrics = [key for key in history.keys() 
                         if key not in ['train_loss', 'val_loss'] 
                         and not key.startswith('val_')]
    
    for metric in additional_metrics:
        if f'val_{metric}' in history:
            plt.figure(figsize=(10, 5))
            plt.plot(history[metric], label=f'Training {metric}')
            plt.plot(history[f'val_{metric}'], label=f'Validation {metric}')
            plt.title(f'Model {metric} During Training')
            plt.xlabel('Epochs')
            plt.ylabel(metric)
            plt.legend()
            plt.grid(True)
            plt.show()
            
            # Save the figure
            plt.savefig(f'results/training_{metric}.png')

def plot_confusion_matrix(y_true, y_pred, classes=['RETROFIT', 'DEMOLISH']):
    """
    Plot confusion matrix for binary classification of retrofit vs demolish
    
    Args:
        y_true: List of true labels
        y_pred: List of predicted labels
        classes: List of class names
    """
    # Calculate confusion matrix
    cm = confusion_matrix(y_true, y_pred, labels=classes)
    
    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.tight_layout()
    plt.show()
    
    # Save the figure
    plt.savefig('results/confusion_matrix.png')
    
    # Calculate and display precision, recall, and F1 scores
    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, labels=classes)
    
    print("Classification Metrics:")
    for i, cls in enumerate(classes):
        print(f"{cls}:")
        print(f"  Precision: {precision[i]:.4f}")
        print(f"  Recall: {recall[i]:.4f}")
        print(f"  F1 Score: {f1[i]:.4f}")
    
    overall_accuracy = accuracy_score(y_true, y_pred)
    print(f"Overall Accuracy: {overall_accuracy:.4f}")

def plot_sdg_coverage(true_rationales, pred_rationales):
    """
    Visualize how well the model covers different SDGs in its rationales
    
    Args:
        true_rationales: List of dictionaries with true rationales for each SDG
        pred_rationales: List of dictionaries with predicted rationales for each SDG
    """
    # Count how many times each SDG is mentioned in a meaningful way
    true_sdg_counts = {'sdg9': 0, 'sdg11': 0, 'sdg12': 0, 'sdg13': 0}
    pred_sdg_counts = {'sdg9': 0, 'sdg11': 0, 'sdg12': 0, 'sdg13': 0}
    
    min_rationale_length = 20  # Minimum characters to consider it a meaningful rationale
    
    for rationale in true_rationales:
        for sdg, text in rationale.items():
            if len(text) >= min_rationale_length:
                true_sdg_counts[sdg] += 1
    
    for rationale in pred_rationales:
        for sdg, text in rationale.items():
            if len(text) >= min_rationale_length:
                pred_sdg_counts[sdg] += 1
    
    # Plot SDG coverage comparison
    sdg_names = ['SDG 9\n(Industry)', 'SDG 11\n(Cities)', 'SDG 12\n(Consumption)', 'SDG 13\n(Climate)']
    true_values = list(true_sdg_counts.values())
    pred_values = list(pred_sdg_counts.values())
    
    plt.figure(figsize=(10, 6))
    x = np.arange(len(sdg_names))
    width = 0.35
    
    plt.bar(x - width/2, true_values, width, label='Expected')
    plt.bar(x + width/2, pred_values, width, label='Generated')
    
    plt.xlabel('Sustainable Development Goals')
    plt.ylabel('Number of Meaningful Mentions')
    plt.title('SDG Coverage in Rationales')
    plt.xticks(x, sdg_names)
    plt.legend()
    plt.tight_layout()
    plt.show()
    
    # Save the figure
    plt.savefig('results/sdg_coverage.png')
    
    # Calculate and display coverage percentages
    print("SDG Coverage Rates:")
    for i, sdg in enumerate(['sdg9', 'sdg11', 'sdg12', 'sdg13']):
        if true_sdg_counts[sdg] > 0:
            coverage_pct = (pred_sdg_counts[sdg] / true_sdg_counts[sdg]) * 100
            print(f"{sdg_names[i]}: {coverage_pct:.1f}%")
        else:
            print(f"{sdg_names[i]}: N/A (no expected mentions)")

def plot_bleu_rouge_scores(bleu_scores, rouge_scores, epochs=None):
    """
    Visualize BLEU and ROUGE scores over time or as final results
    
    Args:
        bleu_scores: Dictionary with BLEU scores or list of dictionaries for scores over time
        rouge_scores: Dictionary with ROUGE scores or list of dictionaries for scores over time
        epochs: Optional list of epoch numbers if plotting scores over time
    """
    if isinstance(bleu_scores, list) and epochs is not None:
        # Plot scores over time
        plt.figure(figsize=(15, 10))
        
        # Plot BLEU scores
        plt.subplot(2, 1, 1)
        plt.plot(epochs, [score['bleu1'] for score in bleu_scores], label='BLEU-1')
        plt.plot(epochs, [score['bleu2'] for score in bleu_scores], label='BLEU-2')
        plt.plot(epochs, [score['bleu3'] for score in bleu_scores], label='BLEU-3')
        plt.plot(epochs, [score['bleu4'] for score in bleu_scores], label='BLEU-4')
        plt.title('BLEU Scores Over Training')
        plt.xlabel('Epochs')
        plt.ylabel('BLEU Score')
        plt.legend()
        plt.grid(True)
        
        # Plot ROUGE scores
        plt.subplot(2, 1, 2)
        plt.plot(epochs, [score['rouge-1']['f'] for score in rouge_scores], label='ROUGE-1')
        plt.plot(epochs, [score['rouge-2']['f'] for score in rouge_scores], label='ROUGE-2')
        plt.plot(epochs, [score['rouge-l']['f'] for score in rouge_scores], label='ROUGE-L')
        plt.title('ROUGE F1 Scores Over Training')
        plt.xlabel('Epochs')
        plt.ylabel('ROUGE Score')
        plt.legend()
        plt.grid(True)
        
        plt.tight_layout()
        plt.show()
        
        # Save the figure
        plt.savefig('results/bleu_rouge_over_time.png')
    else:
        # Plot final scores as bar charts
        plt.figure(figsize=(12, 6))
        
        # BLEU scores
        plt.subplot(1, 2, 1)
        bleu_keys = ['bleu1', 'bleu2', 'bleu3', 'bleu4']
        bleu_values = [bleu_scores[key] for key in bleu_keys]
        plt.bar(range(len(bleu_keys)), bleu_values)
        plt.xticks(range(len(bleu_keys)), ['BLEU-1', 'BLEU-2', 'BLEU-3', 'BLEU-4'])
        plt.title('BLEU Scores')
        plt.ylim(0, 1)
        
        # ROUGE scores
        plt.subplot(1, 2, 2)
        rouge_keys = ['rouge-1', 'rouge-2', 'rouge-l']
        rouge_values = [rouge_scores[key]['f'] for key in rouge_keys]
        plt.bar(range(len(rouge_keys)), rouge_values)
        plt.xticks(range(len(rouge_keys)), ['ROUGE-1', 'ROUGE-2', 'ROUGE-L'])
        plt.title('ROUGE F1 Scores')
        plt.ylim(0, 1)
        
        plt.tight_layout()
        plt.show()
        
        # Save the figure
        plt.savefig('results/bleu_rouge_final.png')

class TrainingHistory:
    """
    Class to track and save training metrics over time
    """
    def __init__(self):
        self.metrics = {
            'train_loss': [],
            'val_loss': [],
            'val_bleu': [],
            'val_rouge': [],
            'val_accuracy': [],
        }
        self.epoch = 0
        
    def update(self, train_loss, val_loss=None, val_bleu=None, val_rouge=None, val_accuracy=None):
        """Update metrics after each epoch"""
        self.metrics['train_loss'].append(train_loss)
        
        if val_loss is not None:
            self.metrics['val_loss'].append(val_loss)
        
        if val_bleu is not None:
            self.metrics['val_bleu'].append(val_bleu)
            
        if val_rouge is not None:
            self.metrics['val_rouge'].append(val_rouge)
            
        if val_accuracy is not None:
            self.metrics['val_accuracy'].append(val_accuracy)
            
        self.epoch += 1
        
    def save(self, filename='results/training_history.json'):
        """Save training history to a JSON file"""
        with open(filename, 'w') as f:
            json.dump(self.metrics, f, indent=2)
            
    def load(self, filename='results/training_history.json'):
        """Load training history from a JSON file"""
        with open(filename, 'r') as f:
            self.metrics = json.load(f)
        self.epoch = len(self.metrics['train_loss'])
        
        self.max_length = max_length
    
    def __len__(self):
        return len(self.buildings)
    
    def __getitem__(self, idx):
        building = self.buildings[idx]
        
        # Create prompt from building assessment data
        prompt = f"Building Assessment:\n"
        prompt += f"Type: {building['building_type']}\n"
        prompt += f"Year Built: {building['year_built']}\n"
        prompt += f"Current Condition: {building['current_condition']}\n"
        prompt += f"Energy Performance: {building['energy_performance']}\n"
        prompt += f"Historical Significance: {building['historical_significance']}\n"
        prompt += f"Location: {building['location']}\n"
        prompt += f"Material Composition: {building['material_composition']}\n"
        prompt += f"Hazardous Materials: {building['hazardous_materials']}\n"
        prompt += f"Adaptation Potential: {building['adaptation_potential']}\n\n"
        prompt += "Recommendation:"
        
        # Get the output (retrofit or demolish recommendation with rationale)
        output = f" {building['recommended_action']}\n\nSDG-Aligned Rationale:\n"
        output += f"- SDG 9 (Industry, Innovation, Infrastructure): {building['sdg_rationale']['sdg9']}\n"
        output += f"- SDG 11 (Sustainable Cities): {building['sdg_rationale']['sdg11']}\n"
        output += f"- SDG 12 (Responsible Consumption): {building['sdg_rationale']['sdg12']}\n"
        output += f"- SDG 13 (Climate Action): {building['sdg_rationale']['sdg13']}\n"
        
        # Tokenize using our advanced tokenization function
        return tokenize_building_data(prompt, output, self.tokenizer, self.max_length)
